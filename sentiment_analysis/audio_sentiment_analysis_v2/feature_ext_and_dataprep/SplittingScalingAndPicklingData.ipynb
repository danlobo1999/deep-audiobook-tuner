{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils, to_categorical\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {\"fdata\": \"../../../assets/audio_sentiment_data_v2/data_features/data_features_and_labels.csv\",\n",
    "         \"save_path\": \"../../../assets/audio_sentiment_data_v2/pickles\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Splitting data into Train, Validation and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(paths[\"fdata\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.10\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['labels'],axis=1),\n",
    "                                                    df.labels, \n",
    "                                                    test_size=1 - train_ratio,\n",
    "                                                    shuffle=True,\n",
    "                                                    random_state=42)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test,\n",
    "                                                y_test, \n",
    "                                                test_size=test_ratio/(test_ratio + validation_ratio),\n",
    "                                                shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2445, 37) (489, 37) (326, 37)\n",
      "(2445,) (489,) (326,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_val.shape, X_test.shape)\n",
    "print(y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_val = sc.transform(X_val)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting y from dataframes to ndarrays\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the targets to one-hot vectors by encoding the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['angry' 'fear' 'happy' 'sad' 'surprise']\n"
     ]
    }
   ],
   "source": [
    "lb = LabelEncoder()\n",
    "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
    "y_val = np_utils.to_categorical(lb.fit_transform(y_val))\n",
    "y_test = np_utils.to_categorical(lb.fit_transform(y_test))\n",
    "print(lb.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickling out the scaler, labels and split data for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = open(f'{paths[\"save_path\"]}/labels.pickle','wb')\n",
    "pickle.dump(lb,outfile)\n",
    "outfile.close()\n",
    "\n",
    "outfile = open(f'{paths[\"save_path\"]}/scaler.pickle', \"wb\")\n",
    "pickle.dump(sc, outfile)\n",
    "outfile.close()\n",
    "\n",
    "outfile = open(f'{paths[\"save_path\"]}/X_train.pickle', \"wb\")\n",
    "pickle.dump(X_train, outfile)\n",
    "outfile.close()\n",
    "\n",
    "outfile = open(f'{paths[\"save_path\"]}/X_val.pickle', \"wb\")\n",
    "pickle.dump(X_val, outfile)\n",
    "outfile.close()\n",
    "\n",
    "outfile = open(f'{paths[\"save_path\"]}/X_test.pickle', \"wb\")\n",
    "pickle.dump(X_test, outfile)\n",
    "outfile.close()\n",
    "\n",
    "outfile = open(f'{paths[\"save_path\"]}/y_train.pickle', \"wb\")\n",
    "pickle.dump(y_train, outfile)\n",
    "outfile.close()\n",
    "\n",
    "outfile = open(f'{paths[\"save_path\"]}/y_val.pickle', \"wb\")\n",
    "pickle.dump(y_val, outfile)\n",
    "outfile.close()\n",
    "\n",
    "outfile = open(f'{paths[\"save_path\"]}/y_test.pickle', \"wb\")\n",
    "pickle.dump(y_test, outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beproj",
   "language": "python",
   "name": "beproj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}