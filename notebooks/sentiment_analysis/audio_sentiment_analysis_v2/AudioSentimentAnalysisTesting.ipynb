{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import subprocess\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "   tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {'files': \"../../../assets/temp\",\n",
    "         \"pickels\": \"../../../assets/audio_sentiment_data_v2/pickles\",\n",
    "         \"models\": \"../../../assets/audio_sentiment_data_v2/models\",}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(paths['files'])\n",
    "files.remove('.gitignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(f\"{paths['pickels']}/scaler.pickle\",\"rb\")\n",
    "scaler = pickle.load(pickle_in)\n",
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(f\"{paths['pickels']}/labels.pickle\",\"rb\")\n",
    "labels = pickle.load(pickle_in)\n",
    "labels.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"hyperband_tuned_best_model_[0.4309597909450531, 0.8404908180236816]\"\n",
    "model = tf.keras.models.load_model(f\"{paths['models']}/{model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(y):\n",
    "    rmse= np.mean(librosa.feature.rms(y=y))\n",
    "    spec_cent = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))\n",
    "    spec_bw = np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr))\n",
    "    rolloff = np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr))\n",
    "    zcr = np.mean(librosa.feature.zero_crossing_rate(y))\n",
    "    chroma_stft = np.mean(librosa.feature.chroma_stft(y=y, sr=sr), axis=1)\n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr), axis=1)\n",
    "\n",
    "    data_features = [rmse,\n",
    "                    spec_cent,\n",
    "                    spec_bw, \n",
    "                    rolloff, \n",
    "                    zcr, \n",
    "                    chroma_stft[0],\n",
    "                    chroma_stft[1],\n",
    "                    chroma_stft[2],\n",
    "                    chroma_stft[3],\n",
    "                    chroma_stft[4],\n",
    "                    chroma_stft[5],\n",
    "                    chroma_stft[6],\n",
    "                    chroma_stft[7],\n",
    "                    chroma_stft[8],\n",
    "                    chroma_stft[9],\n",
    "                    chroma_stft[10],\n",
    "                    chroma_stft[11],\n",
    "                    mfcc[0],\n",
    "                    mfcc[1],\n",
    "                    mfcc[2],\n",
    "                    mfcc[3],\n",
    "                    mfcc[4],\n",
    "                    mfcc[5],\n",
    "                    mfcc[6],\n",
    "                    mfcc[7],\n",
    "                    mfcc[8],\n",
    "                    mfcc[9],\n",
    "                    mfcc[10],\n",
    "                    mfcc[11],\n",
    "                    mfcc[12],\n",
    "                    mfcc[13],\n",
    "                    mfcc[14],\n",
    "                    mfcc[15],\n",
    "                    mfcc[16],\n",
    "                    mfcc[17],\n",
    "                    mfcc[18],\n",
    "                    mfcc[19]\n",
    "                    ]\n",
    "    return data_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_features(X):\n",
    "    return scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# output = pd.DataFrame(columns['file','1','2','3','4','5','6','7','8','9','10'])\n",
    "\n",
    "# for file files:\n",
    "audio, sr = librosa.load(r\"D:\\Projects\\BEProject\\deep-audiobook-tuner\\assets\\audiobooks\\clip_1.wav\", res_type='kaiser_fast', sr=22050*2)\n",
    "\n",
    "buffer = 3 * sr\n",
    "\n",
    "samples_total = len(audio)\n",
    "samples_wrote = 0\n",
    "\n",
    "predictions = []\n",
    "\n",
    "while samples_wrote < samples_total:\n",
    "\n",
    "    #check if the buffer is not exceeding total samples \n",
    "    if buffer > (samples_total - samples_wrote):\n",
    "        buffer = samples_total - samples_wrote\n",
    "\n",
    "    block = audio[samples_wrote : (samples_wrote + buffer)]\n",
    "\n",
    "    data_features = np.array(feature_extraction(block))\n",
    "\n",
    "    scaled_features = scale_features(data_features.reshape(1, -1))\n",
    "\n",
    "    predictions.append(model.predict(scaled_features))\n",
    "\n",
    "    samples_wrote += buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = []\n",
    "for preds in predictions:\n",
    "    preds = preds.argmax(axis=1)\n",
    "    preds = preds.astype(int).flatten()\n",
    "    preds = labels.inverse_transform((preds))\n",
    "    out.append(preds)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.squeeze(predictions, axis=None)\n",
    "l = len(a)\n",
    "a = a.sum(axis=0)\n",
    "a = a/l\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepaudiobooktuner",
   "language": "python",
   "name": "deepaudiobooktuner"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
