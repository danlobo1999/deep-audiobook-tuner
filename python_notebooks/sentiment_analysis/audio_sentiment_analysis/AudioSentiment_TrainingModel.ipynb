{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout, Activation, Flatten, Conv1D, MaxPooling1D, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Memory Growth True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "   tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"../../assets/audio_sentiment_data/X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"../../assets/audio_sentiment_data/y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.reshape(X,(X.shape[0],26,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {\"checkpath\" : \"../../assets/audio_sentiment_data/checkpoints\",\n",
    "         \"modelpath\" : \"../../assets/audio_sentiment_data/models\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layers = [1, 2, 3]\n",
    "conv_layers = [1, 2, 3]\n",
    "no_of_filters = [16, 32, 64]\n",
    "layer_sizes = [64, 128, 256, 512]\n",
    "dropouts = [0.05, 0.1, 0.15, 0.2]\n",
    "batch_sizes = [64, 128, 256]\n",
    "epochs = [200, 300, 400, 500]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for conv_layer in conv_layers:\n",
    "        for filters in no_of_filters:\n",
    "            for layer_size in layer_sizes:\n",
    "                for dropout in dropouts:\n",
    "                    for batch_size in batch_sizes:\n",
    "                        for epoch in epochs:\n",
    "\n",
    "                            model = Sequential()\n",
    "\n",
    "                            model.add(Conv1D(filters=filters, kernel_size=5, input_shape=(26,1)))\n",
    "                            model.add(Activation('relu'))\n",
    "                            model.add(Dropout(dropout))\n",
    "                            model.add(MaxPooling1D(pool_size=2, padding='same'))\n",
    "\n",
    "                            for _ in range(conv_layer-1):\n",
    "                                model.add(Conv1D(filters=filters, kernel_size=3))\n",
    "                                model.add(Activation('relu'))\n",
    "                                model.add(Dropout(dropout))\n",
    "                                model.add(MaxPooling1D(pool_size=2, padding='same'))\n",
    "\n",
    "                            model.add(Flatten())\n",
    "\n",
    "                            for _ in range(dense_layer):\n",
    "                                model.add(Dense(layer_size))\n",
    "                                model.add(Activation('relu'))\n",
    "                                model.add(Dropout(dropout))\n",
    "\n",
    "                            model.add(Dense(10))\n",
    "                            model.add(Activation('softmax'))\n",
    "\n",
    "                            model.compile(optimizer='adam',\n",
    "                                  loss='sparse_categorical_crossentropy',\n",
    "                                  metrics=['accuracy'])\n",
    "\n",
    "                            name = f\"FEA_EXT_DENSE_{dense_layer}DLay_{conv_layer}CLay_{filters}Flt_{layer_size}LSz_{dropout}DO_{int(time.time())}\"\n",
    "                            filepath = f\"{paths['checkpath']}/{name}.best.hdf5\"\n",
    "\n",
    "                            #tensorboard = TensorBoard(log_dir=f\"C:\\\\Users\\\\Lder\\\\Documents\\\\ML_PROJ\\\\log\\\\fincnn15\\\\{NAME}\")\n",
    "\n",
    "                            #es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
    "\n",
    "                            checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "                            hist = model.fit(X, \n",
    "                                             y,\n",
    "                                             batch_size = batch_size,\n",
    "                                             epochs = epoch,\n",
    "                                             callbacks = [checkpoint],\n",
    "                                             validation_split = 0.2\n",
    "        #                                      callbacks=[tensorboard,es,checkpoint]\n",
    "                                            )\n",
    "\n",
    "                            val_acc = hist.history['val_accuracy']\n",
    "\n",
    "                            max_val_acc = max(val_acc)\n",
    "\n",
    "                            max_val_acc_loss = hist.history['val_loss'][val_acc.index(max(val_acc))]\n",
    "\n",
    "                            model_name = f\"{max_val_acc:.4f}acc_{max_val_acc_loss:.4f}loss\"\n",
    "\n",
    "                            model.load_weights(f\"{paths['checkpath']}/{name}.best.hdf5\")\n",
    "\n",
    "                            model.save(f\"{paths['modelpath']}/{model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(f\"{paths['modelpath']}/0.7760acc_0.7978loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beproj",
   "language": "python",
   "name": "beproj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
