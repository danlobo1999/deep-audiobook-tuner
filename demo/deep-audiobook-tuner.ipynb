{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ignored-sacrifice",
   "metadata": {},
   "source": [
    "# deep-audiobook-tuner\n",
    "A system that generates an apt, emotionally pertinent, unique musical score for an audiobook automatically based on the current narrative for the purpose of ameliorating user-experience while being accurate, cost-efficient, and time saving."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-polymer",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "continuous-walnut",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import asyncio\n",
    "from ipywidgets import FileUpload\n",
    "from IPython.display import display, clear_output\n",
    "import keras\n",
    "import ktrain\n",
    "import librosa\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "\n",
    "from deepaudiobooktuner.audio_analysis import *\n",
    "from deepaudiobooktuner.ibm_transcription import *\n",
    "from deepaudiobooktuner.text_analysis import *\n",
    "from deepaudiobooktuner.music_generation import *\n",
    "from deepaudiobooktuner.utils import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "wrapped-organ",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "   tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "killing-crazy",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "#### Uploading an audiobook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "varied-replacement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_change(widget, value):\n",
    "    future = asyncio.Future()\n",
    "    def getvalue(change):\n",
    "        # make the new value available\n",
    "        future.set_result(change.new)\n",
    "        widget.unobserve(getvalue, value)\n",
    "    widget.observe(getvalue, value)\n",
    "    return future\n",
    "\n",
    "async def uploadAudiobook():\n",
    "    # displaying an upload widget\n",
    "    upload = FileUpload(accept='.mp3', multiple=False)\n",
    "    display(upload)\n",
    "    \n",
    "    future = await wait_for_change(upload, 'value')\n",
    "    \n",
    "    uploaded_filename = list(upload.value)[0]\n",
    "    audiobook_path = f'{path(\"../assets/audiobooks\")}/{uploaded_filename}'\n",
    "    \n",
    "    # Saving the audiobook to the audiobook directory\n",
    "    with open(f'{audiobook_path}', 'wb') as output_file: \n",
    "        content = upload.value[uploaded_filename]['content']   \n",
    "        output_file.write(content)\n",
    "    \n",
    "    print(f\"----Saved audiobook at {audiobook_path}\")\n",
    "    \n",
    "    return audiobook_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stainless-alpha",
   "metadata": {},
   "source": [
    "#### Creating a temperory directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "recognized-journalism",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDir(file_path):\n",
    "    file_name = (file_path.split(\"\\\\\")[-1])\n",
    "    file_name = file_name.split(\"/\")[-1][:-4]\n",
    "    creation_time = time.time()\n",
    "\n",
    "    paths = {\n",
    "        \"audio_model\": path(\"../assets/audio_sentiment_data_v2/models/hyperband_tuned_model_final_[0.260879248380661, 0.9069767594337463]/\"),\n",
    "        \"pickles\": path(\"../assets/audio_sentiment_data_v2/pickles\"),\n",
    "        \"text_model\": path(\"../assets/text_sentiment_data/models/bert_model_2/\"),\n",
    "        \"music_model\": path(\"../assets/music_generation/models/MusicTransformerKeyC.pth\"),\n",
    "        \"music_data\": path(\"../assets/music_generation/pickles/\"),\n",
    "        \"wav_save_path\": path(f\"../assets/temp/{file_name}-{creation_time}\"),\n",
    "        \"clips_save_path\": path(f\"../assets/temp/{file_name}-{creation_time}/clips\"),\n",
    "        \"music_samples\": path(\"../assets/music_generation/datasets/vg-midi-annotated\")\n",
    "    }\n",
    "    \n",
    "    # Creating directories in temp to store the converted wav file and the clips\n",
    "    os.mkdir(paths[\"wav_save_path\"])\n",
    "    os.mkdir(paths[\"clips_save_path\"])\n",
    "    \n",
    "    print(\"----Temporary directory created.\")\n",
    "    \n",
    "    return file_name, paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-response",
   "metadata": {},
   "source": [
    "#### Loading assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "guided-biography",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadAssets(paths):\n",
    "    # Loading the audio analyzer model, scaler and classes\n",
    "    current_time = time.time()\n",
    "    audio_model, audio_scaler, audio_classes = loadAudioAssets(\n",
    "        model_path=paths[\"audio_model\"], pickles_path=paths[\"pickles\"]\n",
    "    )\n",
    "    print(f\"----Loaded audio model assets. Time taken: {round(time.time()-current_time, 1)} s\")\n",
    "\n",
    "    # Loading the text analyzer model and classes\n",
    "    current_time = time.time()\n",
    "    text_predictor = ktrain.load_predictor(paths[\"text_model\"])\n",
    "    text_classes = text_predictor.get_classes()\n",
    "    print(f\"----Loaded text model assets. Time taken: {round(time.time()-current_time, 1)} s\")\n",
    "    \n",
    "    # Loading the music generation model and music_data\n",
    "    current_time = time.time()\n",
    "    music_data = load_data(paths['music_data'], 'musicitem_data_save.pkl')\n",
    "    music_model = music_model_learner(music_data, pretrained_path=paths['music_model'])\n",
    "    print(f\"----Loaded music model assets. Time taken: {round(time.time()-current_time, 1)} s\")\n",
    "    \n",
    "    # Setting up IBM\n",
    "    current_time = time.time()\n",
    "    stt = setUpIBM()\n",
    "    print(f\"----Setup IBM transcription service. Time taken: {round(time.time()-current_time, 1)} s\")\n",
    "    \n",
    "    return audio_model, audio_scaler, audio_classes, text_predictor, text_classes, music_data, music_model, stt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-scale",
   "metadata": {},
   "source": [
    "#### Performing text and audio sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "defensive-money",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentimentAnalysis(paths, stt, text_predictor, audio_model, audio_scaler, audio_classes):\n",
    "    transcriptions = [] # List to store transcriptions of all the segmented clips\n",
    "    emotions = [] # List to store emotions of all the segmented clips\n",
    "    \n",
    "    for i, file_name in enumerate(glob(f'{paths[\"clips_save_path\"]}/*.wav')):\n",
    "        current_time = time.time()\n",
    "        print(f\"\\nProcessing clip {i+1}:\")\n",
    "\n",
    "        # Performing text sentiment analysis\n",
    "        print(\"----Text sentiment analysis\") \n",
    "        text_emotions, transcription = analyzeText(\n",
    "            file_name=file_name, stt=stt, predictor=text_predictor\n",
    "        )\n",
    "        \n",
    "        # Performing text sentiment analysis\n",
    "        print(\"----Audio sentiment analysis\")\n",
    "        audio_emotions = analyzeAudio(\n",
    "            file_name=file_name, model=audio_model, scaler=audio_scaler\n",
    "        )\n",
    "        \n",
    "        # Taking the average of text and audio emotions\n",
    "        print(\"----Predicting final emotion\")\n",
    "        weighted_text_emotions = text_emotions * 0.5\n",
    "        weighted_audio_emotions = audio_emotions * 0.5\n",
    "        weighted_emotions = weighted_text_emotions + weighted_audio_emotions\n",
    "\n",
    "        # Picking the dominant emotion and labelling it\n",
    "        weighted_emotions = weighted_emotions.argmax()\n",
    "        weighted_emotions = weighted_emotions.astype(int).flatten()\n",
    "        final_emotion = audio_classes.inverse_transform((weighted_emotions))\n",
    "\n",
    "        transcriptions.append(transcription)\n",
    "        emotions.append(final_emotion)\n",
    "        \n",
    "        print(f\"----Clip {i+1} processed. Time taken: {round(time.time()-current_time, 1)} s\")\n",
    "        \n",
    "    return transcriptions, emotions  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floral-standing",
   "metadata": {},
   "source": [
    "## Main Function\n",
    "**Input:** Audiobook in mp3 format.  \n",
    "\n",
    "**Procedure:**\n",
    "- The audiobook is segmented into 30 second clips.\n",
    "- Each segment is analyzed by the audio and text analyzers.\n",
    "- A sentiment is predicted for each segment of the audiobook.\n",
    "- Music clips are generated for the four emotions (Angry, Happy, Neutral and Sad) \n",
    "\n",
    "**Output:**\n",
    "- Audiobook segments with its transcription and predicted emotion\n",
    "- Music clips for each emotion (Angry, Happy, Neutral and Sad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "mysterious-buying",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepAudiobookTuner(audiobook_path):\n",
    "    # Creating a temperory directory to store the segmented audiobook clips and generated music clips\n",
    "    print(\"\\nCreating temporary directory.\")\n",
    "    file_name, paths = createDir(audiobook_path)\n",
    "\n",
    "    # Loading assets.\n",
    "    print(\"\\nLoading assets.\")\n",
    "    audio_model, audio_scaler, audio_classes, text_predictor, text_classes, music_data, music_model, stt = loadAssets(paths)\n",
    "    \n",
    "    \n",
    "    # Converting the mp3 file to a wav file\n",
    "    print(\"\\nConverting mp3 to wav\")\n",
    "    wav_file_path = convertToWav(\n",
    "        file_name=file_name, file_path=audiobook_path, save_path=paths[\"wav_save_path\"]\n",
    "    )\n",
    "    \n",
    "    # Segmenting the audio file into 30 second clips\n",
    "    print(\"\\nSegmenting audiobook\")\n",
    "    segmentAudioFile(\n",
    "        file_name=file_name, file_path=wav_file_path, save_path=paths[\"clips_save_path\"]\n",
    "    )\n",
    "    \n",
    "    # Performing Sentiment Analysis\n",
    "    print(\"\\n\\nPerforming sentiment analysis\")\n",
    "    transcriptions, emotions = sentimentAnalysis(paths, stt, text_predictor, audio_model, audio_scaler, audio_classes)\n",
    "    \n",
    "    # Generating music\n",
    "    print(\"\\n\\nGenerating music\")\n",
    "    \n",
    "    \n",
    "    return transcriptions, emotions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-technician",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "manufactured-romantic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Upload an audiobook in mp3 format.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f27fc1f278b476192cca16d33562596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value={}, accept='.mp3', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Saved audiobook at D:\\Projects\\BEProject\\deep-audiobook-tuner\\assets\\audiobooks/Alice_in_Wonderland_test.mp3\n"
     ]
    }
   ],
   "source": [
    "# Taking an audiobook in mp3 format as the input\n",
    "print(\"\\nUpload an audiobook in mp3 format.\\n\")\n",
    "audiobook_path = asyncio.ensure_future(uploadAudiobook())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-stevens",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepAudiobookTuner(audiobook_path.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-three",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-indication",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "northern-discount",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating temporary directory.\n",
      "----Temporary directory created.\n",
      "\n",
      "Loading assets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Danny\\miniconda3\\envs\\deepaudiobooktuner\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator StandardScaler from version 0.24.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Danny\\miniconda3\\envs\\deepaudiobooktuner\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.24.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Loaded audio model assets. Time taken: 2.6 s\n",
      "----Loaded text model assets. Time taken: 8.5 s\n",
      "----Loaded music model assets. Time taken: 3.8 s\n",
      "----Setup IBM transcription service. Time taken: 0.0 s\n"
     ]
    }
   ],
   "source": [
    "# Creating a temperory directory to store the segmented audiobook clips and generated music clips\n",
    "print(\"\\nCreating temporary directory.\")\n",
    "file_name, paths = createDir(audiobook_path.result())\n",
    "\n",
    "# Loading assets.\n",
    "print(\"\\nLoading assets.\")\n",
    "audio_model, audio_scaler, audio_classes, text_predictor, text_classes, music_data, music_model, stt = loadAssets(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "lightweight-olympus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../assets/music_generation/datasets/vg-midi-annotated/Sad\\Final_Fantasy_7_OnThatDay5YearsAgo.mid\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='326' class='' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      81.50% [326/400 00:14<00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_song = generateMusic('Sad', \"../assets/music_generation/datasets/vg-midi-annotated\", music_model, music_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "independent-receipt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <div id='midiPlayerDiv55388'></div>\n",
       "                <link rel=\"stylesheet\" href=\"//cuthbertLab.github.io/music21j/css/m21.css\"\n",
       "                    type=\"text/css\" />\n",
       "                <script>\n",
       "                require.config({\n",
       "                    paths: {'music21': '//cuthbertLab.github.io/music21j/src/music21'}\n",
       "                });\n",
       "                require(['music21'], function() {\n",
       "                               mp = new music21.miditools.MidiPlayer();\n",
       "                               mp.addPlayer('#midiPlayerDiv55388');\n",
       "                               mp.base64Load('data:audio/midi;base64,TVRoZAAAAAYAAQACBABNVHJrAAAAGgD/UQMHoSAA/1kCAAAA/1gEBAIYCIgA/y8ATVRyawAABQsA/wMFUGlhbm8AwAAA4ABAAMAAiACQRVoAkDlaAJA8WgCQQFqOAIBFAIIAkEdahgCARwCCAJBIWoYAgDkAAIA8AACAQAAAgEgAggCQOVoAkD5aAJBDWgCQT1qOAIA5AACAPgAAgEMAAIBPAIIAkDlaAJA+WgCQQloAkE5ajgCAOQAAgD4AAIBCAACATgCCAJA5WgCQPFoAkEFaiACQRVqGAIBFAIIAkEhahgCASACCAJBNWoYAgDkAAIA8AACAQQAAgE0AggCQOVoAkDxaAJBAWgCQTFqOAIA5AACAPAAAgEAAAIBMAIIAkDlaAJA8WgCQQVoAkE1ajgCAOQAAgDwAAIBBAACATQCCAJA5WgCQPFoAkEBaAJBFWgCQUVqOAIA5AACAPAAAgEAAAIBFAACAUQCCAJA4WgCQO1oAkEBaAJBEWgCQUFqOAIA4AACAOwAAgEAAAIBEAACAUACCAJA4WgCQO1oAkEBaAJBHWgCQU1qOAIA4AACAOwAAgEAAAIBHAACAUwCCAJA5WgCQPFoAkEBaiACQSloAkFZahgCAOQAAgDwAAIBAAACASgAAgFYAggCQOVoAkD5aAJBBWgCQSloAkFZajgCAOQAAgD4AAIBBAACASgAAgFYAggCQOVoAkDxaAJBAWgCQRVoAkExaAJBYWo4AgDkAAIA8AACAQAAAgEUAAIBMAACAWACCAJA5WgCQPFoAkEBaAJBFWgCQSFoAkFRajgCAOQAAgDwAAIBAAACARQAAgEgAAIBUAIIAkD5aAJBDWgCQR1qOAIA+AACAQwAAgEcAggCQPloAkEFaAJBFWo4AgD4AAIBBAACARQCCAJBIWgCQPloAkEFahgCASACCAJBNWoYAgD4AAIBBAACATQCCAJA8WgCQQFoAkENaAJBMWo4AgDwAAIBAAACAQwAAgEwAggCQOVoAkDxaAJBBWgCQTVqOAIA5AACAPAAAgEEAAIBNAIIAkDlaAJA8WgCQQFoAkEVaAJBRWo4AgDkAAIA8AACAQAAAgEUAAIBRAIIAkDhaAJA7WgCQQFoAkERaAJBQWo4AgDgAAIA7AACAQAAAgEQAAIBQAIIAkDhaAJA7WgCQQFoAkEdaAJBTWo4AgDgAAIA7AACAQAAAgEcAAIBTAIIAkDlaAJA8WgCQQFqIAJBKWgCQVlqGAIA5AACAPAAAgEAAAIBKAACAVgCCAJA5WgCQPloAkEFaAJBKWgCQVlqOAIA5AACAPgAAgEEAAIBKAACAVgCCAJA5WgCQPFoAkEBaAJBFWgCQTFoAkFhajgCAOQAAgDwAAIBAAACARQAAgEwAAIBYAIIAkDlaAJA8WgCQQFoAkEVaAJBIWgCQVFqOAIA5AACAPAAAgEAAAIBFAACASAAAgFQAggCQPloAkENaAJBHWo4AgD4AAIBDAACARwCCAJA5WgCQPloAkEFaAJBFWgCQUVqOAIA5AACAPgAAgEEAAIBFAACAUQCCAJA3WgCQO1oAkD5aAJBDWgCQT1qOAIA3AACAOwAAgD4AAIBDAACATwCCAJA2WgCQOVoAkD5aAJBCWgCQTlqOAIA2AACAOQAAgD4AAIBCAACATgCCAJA2WgCQOVoAkD5aAJBKWgCQVlqOAIA2AACAOQAAgD4AAIBKAACAVgCCAJA3WgCQO1oAkEBaAJBDWgCQTFoAkFhajgCANwAAgDsAAIBAAACAQwAAgEwAAIBYAIgA/y8A');\n",
       "                        });\n",
       "                </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_song.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "posted-nurse",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.875"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_song.stream.seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-genetics",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepaudiobooktuner",
   "language": "python",
   "name": "deepaudiobooktuner"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
